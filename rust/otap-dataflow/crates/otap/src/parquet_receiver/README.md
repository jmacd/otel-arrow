# Parquet Receiver Implementation

This directory contains the implementation of a Parquet Receiver for the OTAP dataflow engine. The receiver reads parquet files generated by the parquet exporter and reconstructs OTAP data for downstream processing.

## Overview

The Parquet Receiver is designed as a **hackathon MVP** focused on demonstrating the concept of parquet-to-OTAP reconstruction. It provides:

- **DataFusion-based querying** for efficient parquet file reading
- **Multi-table joins** to reconstruct relationships between main signals and attributes  
- **File discovery** with partition-aware scanning
- **OTAP reconstruction** that converts DataFusion results back to OtapArrowRecords
- **Pipeline integration** compatible with the existing otap-dataflow framework

## Architecture

```
ParquetReceiver
â”œâ”€â”€ file_discovery.rs    # Scans directories for new parquet files
â”œâ”€â”€ query_engine.rs      # DataFusion-based multi-table queries  
â”œâ”€â”€ reconstruction.rs    # Converts DataFusion results to OTAP format
â”œâ”€â”€ config.rs           # Configuration parsing and validation
â””â”€â”€ error.rs            # Error handling for parquet operations
```

## Key Features

### ğŸ” **Smart File Discovery**
- Monitors main signal directories (`logs/`, `spans/`, `univariate_metrics/`)
- Extracts partition IDs from directory structure (`_part_id=<uuid>`)
- Tracks processed files to avoid duplicates
- Supports configurable minimum file age for safety

### âš¡ **DataFusion Query Engine**
- Creates isolated SessionContext per operation
- Registers multiple parquet tables for joins
- Executes optimized SQL queries with LEFT JOINs
- Leverages DataFusion's built-in memory management

### ğŸ”„ **OTAP Reconstruction**
- Converts DataFusion RecordBatch results to OtapArrowRecords
- Supports logs, traces, and metrics reconstruction
- Handles schema variations gracefully
- Combines multiple record batches efficiently

### ğŸ­ **Pipeline Integration**
- Implements the standard Receiver trait
- Uses local receiver pattern (non-shared)
- Supports standard control messages (shutdown, config)
- Integrates with existing effect handlers

## Usage

### Configuration

```yaml
nodes:
  parquet_receiver:
    kind: receiver
    plugin_urn: "urn:otel:otap:parquet:receiver"
    config:
      base_uri: "/tmp/output_parquet_files"
      signal_types: ["logs", "traces", "metrics"] 
      polling_interval: "5s"
      processing_options:
        batch_size: 1000
        min_file_age: "10s"
        validate_relations: false
```

### Running

```bash
# Test the implementation
./test_parquet_receiver.sh

# Run with demo config  
./target/release/df_engine --config configs/parquet-receiver-demo.yaml
```

## File Structure Expectations

The receiver expects parquet files organized in the star-schema format produced by the parquet exporter:

```
base_directory/
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ _part_id=<uuid>/
â”‚       â””â”€â”€ part-<timestamp>-<uuid>.parquet
â”œâ”€â”€ log_attrs/
â”‚   â””â”€â”€ _part_id=<uuid>/
â”‚       â””â”€â”€ part-<timestamp>-<uuid>.parquet  
â”œâ”€â”€ resource_attrs/
â”‚   â””â”€â”€ _part_id=<uuid>/
â”‚       â””â”€â”€ part-<timestamp>-<uuid>.parquet
â””â”€â”€ scope_attrs/
    â””â”€â”€ _part_id=<uuid>/
        â””â”€â”€ part-<timestamp>-<uuid>.parquet
```

## Implementation Status

### âœ… **Completed (Hackathon MVP)**
- [x] Basic file discovery and partition scanning
- [x] DataFusion integration for parquet reading  
- [x] Multi-table query execution with joins
- [x] OTAP data reconstruction for logs
- [x] Receiver trait implementation and pipeline integration
- [x] Error handling and logging
- [x] Basic configuration parsing
- [x] Unit tests for core functionality

### ğŸš§ **Future Enhancements**
- [ ] Advanced schema evolution handling
- [ ] Cross-partition time-range queries  
- [ ] Streaming/chunked processing for large files
- [ ] Checkpointing and resume capabilities
- [ ] Performance optimizations and metrics
- [ ] Production-grade error recovery
- [ ] Dynamic configuration updates

## Testing

The implementation includes comprehensive unit tests:

```bash
# Run parquet receiver tests
cargo test --package otap-df-otap parquet_receiver

# Run with output
cargo test --package otap-df-otap parquet_receiver -- --nocapture
```

## Design Decisions

### **DataFusion-First Approach**
- Leverages proven parquet reading and query optimization
- Handles memory management and streaming automatically  
- Provides built-in schema inference and evolution support
- Enables complex multi-table joins with standard SQL

### **Partition Isolation**
- Processes one partition at a time to ensure data consistency
- Avoids complex cross-partition coordination
- Simplifies error handling and recovery

### **Hackathon Scope**
- Prioritizes correctness and demo-ability over performance
- Skips production concerns like file locking and checkpointing
- Focuses on logs reconstruction as primary use case
- Uses simplified error handling (log and continue)

## Dependencies

- `datafusion`: Core query engine for parquet processing
- `arrow`: Record batch operations and schema handling  
- `parquet`: File format support (via DataFusion)
- `uuid`: Partition ID parsing and validation
- `serde`: Configuration deserialization
- `tokio`: Async runtime for file I/O and timers

## Error Handling

The receiver is designed to be resilient:
- Logs errors and continues processing other files
- Skips corrupted or incomplete files
- Handles missing related tables gracefully  
- Provides detailed error context for debugging

## Performance Characteristics

- **Memory Usage**: Bounded by DataFusion's memory pool
- **I/O Pattern**: Sequential reads with DataFusion optimizations
- **Concurrency**: Single-threaded processing per partition
- **Throughput**: Optimized for correctness over speed (hackathon scope)

---

*This implementation demonstrates the feasibility of parquet-to-OTAP reconstruction and provides a solid foundation for future production development.*