settings:
  default_pipeline_ctrl_msg_channel_size: 100
  default_node_ctrl_msg_channel_size: 100
  default_pdata_channel_size: 100

nodes:
  # Sampling receiver node
  sampling_receiver:
    kind: receiver
    plugin_urn: "urn:otel:otap:sampling:receiver"
    out_ports:
      out_port:
        destinations:
          - debug_processor
        dispatch_strategy: round_robin
    config:
      # Base directory containing parquet files generated by exporter
      base_uri: "file:///home/jmacd/src/otel/otel-arrow-tail-sampler/rust/otap-dataflow/output_parquet_files"
      # Signal types to process
      signal_types: ["logs"]
      
      # Temporal processing configuration - optimized for testing existing data
      temporal:
        window_granularity: "30s"       # Smaller windows for quicker processing
        processing_delay: "1s"          # Short delay since data is static
        max_clock_drift: "1s"           # Minimal clock drift for testing
        max_file_duration: "5m"         # Allow for larger time spans in test files
      
      # Default pass-through query (100% sampling) - limited for testing
      query: |
        SELECT *
        FROM log_attributes
        WHERE timestamp_unix_nano >= {window_start_ns}
          AND timestamp_unix_nano < {window_end_ns}
        ORDER BY _part_id, parent_id, key
        LIMIT 50
      
      # Performance tuning - conservative settings for testing
      performance:
        batch_size: 100
        enable_arrow_optimization: true
        memory_limit: "512MB"
        max_concurrent_files: 5
        target_partitions: 2
  
  # Debug processor to show the reconstructed data
  debug_processor:
    kind: processor
    plugin_urn: "urn:otel:debug:processor"
    out_ports:
      out_port:
        destinations:
          - noop_exporter
        dispatch_strategy: round_robin
    config:
      verbosity: detailed

  # NoOp exporter to act as a sink
  noop_exporter:
    kind: exporter
    plugin_urn: "urn:otel:noop:exporter"
    config: {}